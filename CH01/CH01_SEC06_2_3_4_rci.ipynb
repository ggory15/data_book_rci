{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTE EIGENFACES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "mat_contents = scipy.io.loadmat(os.path.join('..','DATA','allFaces.mat'))\n",
    "faces = mat_contents['faces']\n",
    "m = int(mat_contents['m'])\n",
    "n = int(mat_contents['n'])\n",
    "nfaces = np.ndarray.flatten(mat_contents['nfaces'])\n",
    "\n",
    "# We use the first 36 people for training data\n",
    "trainingFaces = faces[:,:np.sum(nfaces[:36])]\n",
    "print(trainingFaces.shape) # 모든 얼굴\n",
    "\n",
    "avgFace = np.mean(trainingFaces,axis=1) # size n*m by 1\n",
    "print(avgFace)\n",
    "print(avgFace.shape)\n",
    "\n",
    "# Compute eigenfaces on mean-subtracted training data\n",
    "X = trainingFaces - np.tile(avgFace,(trainingFaces.shape[1],1)).T # (모든 얼굴) - (평균 얼굴에서 평균 열 벡터)\n",
    "U, S, VT = np.linalg.svd(X,full_matrices=0) # 경제적 SVD 계산\n",
    "\n",
    "# 약 2400개의 고유면을 가지고 있다.\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(121)\n",
    "img_avg = ax1.imshow(np.reshape(avgFace,(m,n)).T)\n",
    "img_avg.set_cmap('gray')\n",
    "plt.axis('off')\n",
    "\n",
    "ax2 = fig1.add_subplot(122)\n",
    "img_u1 = ax2.imshow(np.reshape(U[:,0],(m,n)).T)\n",
    "img_u1.set_cmap('gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ reshape face = x_{hat} = U_r * (U_r)^T * x $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now show eigenface reconstruction of image that was omitted from test set\n",
    "from matplotlib.image import imread\n",
    "\n",
    "dog = True\n",
    "\n",
    "if (not dog):\n",
    "    testFace = faces[:,np.sum(nfaces[:36])] # First face of person 37, new face\n",
    "    plt.imshow(np.reshape(testFace,(m,n)).T)\n",
    "else:\n",
    "    testDog = imread(os.path.join('..','DATA','dog.jpg'))\n",
    "    testDog = np.mean(testDog, -1); # Convert RGB to grayscale\n",
    "    m1, n1 = np.shape(testDog)\n",
    "    testFace = np.zeros((m,n))\n",
    "\n",
    "    for i in range(0, m):\n",
    "        for j in range(0, n):            \n",
    "            testFace[i, j] = testDog[i * int (m1/m), j * int (n1/n)]\n",
    "    plt.imshow(testFace)\n",
    "    testFace = np.reshape(testFace, m*n)\n",
    "\n",
    "\n",
    "plt.set_cmap('gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "testFaceMS = testFace - avgFace\n",
    "r_list = [25, 50, 100, 200, 400, 800, 1600] # rank에 따른 이미지 재구성\n",
    "\n",
    "for r in r_list:\n",
    "\n",
    "    reconFace = avgFace + U[:,:r]  @ U[:,:r].T @ testFaceMS #compute : 평균얼굴 + x_hat\n",
    "\n",
    "    img = plt.imshow(np.reshape(reconFace,(m,n)).T)\n",
    "    img.set_cmap('gray')\n",
    "    plt.title('r = ' + str(r))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# r값이 증가함에 따라 점점 실제 사진과 가까워지게 된다.\n",
    "# 위상변화가 400모드 주변에서 발생하여 실제사람처럼 보이게 된다. >  따라서 400모드가 주어지면 실제 original image 사람을 선택할 수 있다.\n",
    "# 중요한 의미 : 상대적으로 적은 양의 정보만으로도 선택할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Project person 2 and 7 onto PC5 and PC6 \n",
    "# 라이브러리에서 무작위로 선택한 사람의 얼굴을 가져와서 투영.\n",
    "\n",
    "P1num = 2 # Person number 2 \n",
    "P2num = 7 # Person number 7 \n",
    "\n",
    "P1 = faces[:,np.sum(nfaces[:(P1num-1)]):np.sum(nfaces[:P1num])]\n",
    "P2 = faces[:,np.sum(nfaces[:(P2num-1)]):np.sum(nfaces[:P2num])]\n",
    "# print(P1.shape)\n",
    "# print(P2.shape)\n",
    "\n",
    "P1 = P1 - np.tile(avgFace,(P1.shape[1],1)).T\n",
    "P2 = P2 - np.tile(avgFace,(P2.shape[1],1)).T\n",
    "\n",
    "PCAmodes = [5, 6] # Project onto PCA modes 5 and 6 #U행렬의 5,6번째 행렬을 선택\n",
    "PCACoordsP1 = U[:,PCAmodes-np.ones_like(PCAmodes)].T @ P1 \n",
    "PCACoordsP2 = U[:,PCAmodes-np.ones_like(PCAmodes)].T @ P2\n",
    "\n",
    "plt.plot(PCACoordsP1[0,:],PCACoordsP1[1,:],'d',color='k',label='Person 2')\n",
    "plt.plot(PCACoordsP2[0,:],PCACoordsP2[1,:],'^',color='r',label='Person 7')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사람2 와 사람7이 주성분 공간에서 클러스터 되어있는것을 확인할 수 있다.\n",
    "* plot이미지는 효율적으로 정확한 분류기를 구축할 수 있음을 알려줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#일곱번째 사람의 이미지\n",
    "\n",
    "img = plt.imshow(np.reshape(P2[:,0],(m,n)).T)\n",
    "img.set_cmap('gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#두번째 사람의 이미지\n",
    "\n",
    "img = plt.imshow(np.reshape(P1[:,0],(m,n)).T)\n",
    "img.set_cmap('gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
